{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMzUM/RWitc7sf7BTt2yIju",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomtomh512/UBH24/blob/main/UBH24_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install opendatasets"
   ],
   "metadata": {
    "id": "ECPvJKsclfX2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f7d2d7be-5b24-42bf-af63-7e7afcc8aeab"
   },
   "execution_count": 80,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.6)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.2.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.10)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xu_BiAWNkR73"
   },
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pair_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/rm1000/skin-cancer-isic-images\")"
   ],
   "metadata": {
    "id": "6zMU6ejWkbBB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c04cf3ad-e4cc-4621-8c4b-b760c1c25fb2"
   },
   "execution_count": 82,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Skipping, found downloaded files in \"./skin-cancer-isic-images\" (use force=True to force download)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize((128, 128)),          # Resize to a 128x128\n",
    "  transforms.Grayscale(),                 # Convert to grayscale\n",
    "  transforms.ToTensor(),                  # Convert to tensor\n",
    "  transforms.Normalize([0.5], [0.5])      # Normalize\n",
    "])"
   ],
   "metadata": {
    "id": "0szSOMcKlHxs"
   },
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = datasets.ImageFolder(root='skin-cancer-isic-images', transform=transform)\n",
    "test_data = datasets.ImageFolder(root='skin-cancer-isic-images', transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size = 30, shuffle = True)\n",
    "test_loader = DataLoader(test_data, batch_size = 30, shuffle = False)"
   ],
   "metadata": {
    "id": "A-KOM0sGlV7T"
   },
   "execution_count": 84,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3, 1)       # input, output, kernel, stride\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "    self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "    self.conv4 = nn.Conv2d(128, 256, 3, 1)\n",
    "\n",
    "    self.fc1 = nn.Linear(256 * 6 * 6, 512)    # 256 * 6 * 6 -> 512\n",
    "    self.fc2 = nn.Linear(512, 256)\n",
    "    self.fc3 = nn.Linear(256, 128)\n",
    "    self.fc4 = nn.Linear(128, 2)\n",
    "\n",
    "  def forward(self, X):\n",
    "    X = F.relu(self.conv1(X))\n",
    "    X = F.max_pool2d(X, 2, 2)\n",
    "    X = F.relu(self.conv2(X))\n",
    "    X = F.max_pool2d(X, 2, 2)\n",
    "    X = F.relu(self.conv3(X))\n",
    "    X = F.max_pool2d(X, 2, 2)\n",
    "    X = F.relu(self.conv4(X))\n",
    "    X = F.max_pool2d(X, 2, 2)\n",
    "\n",
    "    X = X.view(-1, 256 * 6 * 6)\n",
    "\n",
    "    X = F.relu(self.fc1(X))\n",
    "    X = F.relu(self.fc2(X))\n",
    "    X = F.relu(self.fc3(X))\n",
    "    X = self.fc4(X)\n",
    "\n",
    "    return F.log_softmax(X, dim = 1)"
   ],
   "metadata": {
    "id": "CVe6Uyiml4jl"
   },
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = CNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ],
   "metadata": {
    "id": "k0doGfN2nvmg"
   },
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    images, labels = data\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * images.size(0)\n",
    "\n",
    "  epoch_loss = running_loss / len(train_loader.dataset)\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "id": "sl83FFlioBWj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fdf66448-f430-44f5-ea65-898dec79c10f"
   },
   "execution_count": 87,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10, Loss: 0.686\n",
      "Epoch 2/10, Loss: 0.631\n",
      "Epoch 3/10, Loss: 0.586\n",
      "Epoch 4/10, Loss: 0.549\n",
      "Epoch 5/10, Loss: 0.507\n",
      "Epoch 6/10, Loss: 0.453\n",
      "Epoch 7/10, Loss: 0.418\n",
      "Epoch 8/10, Loss: 0.370\n",
      "Epoch 9/10, Loss: 0.353\n",
      "Epoch 10/10, Loss: 0.324\n",
      "Finished Training\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for i, data in enumerate(test_loader, 0):\n",
    "    images, labels = data\n",
    "\n",
    "    outputs = model(images)\n",
    "    predicted = outputs.argmax(dim=1)\n",
    "    total += labels.size(0)\n",
    "\n",
    "    # Count number of matches\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f'Accuracy: {accuracy:.3f}%')"
   ],
   "metadata": {
    "id": "TgcpjTHJoiny",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f8f91d0b-a3b4-4f4e-8a0e-d8d2f8c6d2f1"
   },
   "execution_count": 88,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 88.474%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), 'model_0.pt')"
   ],
   "metadata": {
    "id": "InG4Cblg3kkG"
   },
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')     # 'L' = Single channel image, grayscale\n",
    "    transform = transforms.Compose([                # Match transform composition\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "    image = transform(image)\n",
    "    return image"
   ],
   "metadata": {
    "id": "MDIUAZxY4IM0"
   },
   "execution_count": 91,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "image_path = 'skin-cancer-isic-images/malignant/0056.jpg'\n",
    "processed_image = preprocess_image(image_path)\n",
    "processed_image = processed_image.unsqueeze(0)  # Add batch dimension\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_prediction = model(processed_image)\n",
    "\n",
    "print(new_prediction.argmax())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKyNMb7p4PTC",
    "outputId": "8e1d92a5-ca45-448e-99a2-d010d8410d75"
   },
   "execution_count": 99,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1)\n"
     ]
    }
   ]
  }
 ]
}
